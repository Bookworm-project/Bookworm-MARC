{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports. Overzealous, copied from a different notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymarc\n",
    "import random\n",
    "from bookwormMARC.bookwormMARC import BRecord\n",
    "from bookwormMARC.bookwormMARC import parse_record\n",
    "from bookwormMARC.hathi_methods import hathi_record_yielder\n",
    "from bookwormMARC.bookwormMARC import LCCallNumber\n",
    "import bz2\n",
    "import bookwormMARC\n",
    "import sys\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "#all_files = hathi_record_yielder()\n",
    "import pymarc\n",
    "import ujson as json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This converts a json object into a MARC class so the existing methods will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def obj_to_marc(jobj):        \n",
    "    rec = BRecord()\n",
    "    rec.leader = jobj['leader']\n",
    "    for field in jobj['fields']:\n",
    "        k,v = list(field.items())[0]\n",
    "        if 'subfields' in v and hasattr(v,'update'):\n",
    "            # flatten m-i-j dict to list in pymarc\n",
    "            subfields = []\n",
    "            for sub in v['subfields']:\n",
    "                for code,value in sub.items():\n",
    "                    subfields.extend((code,value))\n",
    "            fld = pymarc.Field(tag=k,subfields=subfields,indicators=[v['ind1'], v['ind2']])\n",
    "        else:\n",
    "            fld = pymarc.Field(tag=k,data=v)\n",
    "        rec.add_field(fld)\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class has the base names of the files and my directory structure hard-coded in: run elsewhere, you'll need to change that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class All_Hathi(object):\n",
    "    \"\"\"\n",
    "    A generator that will yield, one at a time, a bookworm-suitable JSON file for every document in the Hathi Trust.\n",
    "    \"\"\"\n",
    "    def __init__(self,root = \"/drobo/hathi_metafiles\"):\n",
    "        self.files = []\n",
    "        if not root.endswith(\"/\"):\n",
    "            # I always forget to end dirs with a slash.\n",
    "            root = root + \"/\"\n",
    "        base_names = [\"meta_ic.json.bz2\",\"meta_pd_google.json.bz2\",\n",
    "                      \"meta_pd_open_access.json.bz2\",\"meta_restricted.json.bz2\"]\n",
    "        for name in base_names:\n",
    "            self.files.append(root + name)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        The iterator goes through, in descending depth:\n",
    "        1. Every giant file of the Hathi dumps;\n",
    "        2. Every record in each file;\n",
    "        3. Every item in each record.\n",
    "        \"\"\"\n",
    "        for fn in self.files:\n",
    "            sys.stdout.write(\"Reading fn\\n\")\n",
    "            file = bz2.BZ2File(fn)\n",
    "            for line in file:\n",
    "                record = obj_to_marc(json.loads(line))\n",
    "                for vol in record.hathi_bookworm_dicts():\n",
    "                    yield vol\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's where we write it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_hathi = All_Hathi()\n",
    "dump = gzip.open(\"/drobo/hathi_metafiles/jsoncatalog_full.txt.gz\",\"w\")\n",
    "for i,vol in enumerate(all_hathi):\n",
    "    if i % 250000 == 0:\n",
    "        sys.stdout.write(\"Reading item no. \" + str(i) + \"\\n\")\n",
    "    dump.write(json.dumps(vol) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
