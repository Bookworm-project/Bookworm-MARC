{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is a quick demo of what sort of data I'm pulling out with Hathi-Specific features of the Bookworm-MARC library.\n",
    "\n",
    "\n",
    "First just some basic imports, including from this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymarc\n",
    "import random\n",
    "import json\n",
    "from bookwormMARC.bookwormMARC import parse_record\n",
    "from bookwormMARC.hathi_methods import hathi_record_yielder\n",
    "from bookwormMARC.bookwormMARC import LCCallNumber\n",
    "\n",
    "import bookwormMARC\n",
    "import sys\n",
    "import os\n",
    "from collections import defaultdict\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_files = hathi_record_yielder()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example output\n",
    "\n",
    "Here is an example of the output of this script on Hathi books: 5 randomly selected records from the first 50000 or so in the DPLA dump. This is usually, note, more than 5 *items*: Hathi groups multiple items into a single record.\n",
    "\n",
    "Note that we're using a custom superset of the pymarc.Record class called `BRecord`. This adds a number of functions that make it easier--for instance--to pull out a dictionary with the categories that may be useful for Bookworms in a variety of ways.\n",
    "\n",
    "Each of the keys here is something that might make sense to chart or analyze. We want to know the scanner so that we can see if there are OCR effects or something that might be relevant. We want the library so we can see how shifting library composition affects time series. It might make sense to build up miniature bookworms for particular authors, or publishers, etc.\n",
    "\n",
    "To start with, I just print four random records from the first 500 or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"cataloging_source\": \" \",\n",
      "  \"cntry\": \"enk\",\n",
      "  \"contributing_library\": \"nrlf\",\n",
      "  \"date\": 1901,\n",
      "  \"filename\": \"uc1.$b556662\",\n",
      "  \"first_author_birth\": 1873,\n",
      "  \"first_author_death\": 1933,\n",
      "  \"first_author_name\": \"Savoia, Luigi Amedeo di, duca degli Abruzzi, 1873-1933.\",\n",
      "  \"first_place\": \"London,\",\n",
      "  \"first_publisher\": \"H.W. Bell,\",\n",
      "  \"government_document\": \" \",\n",
      "  \"item_date\": 1901,\n",
      "  \"language\": \"eng\",\n",
      "  \"lc0\": \"G\",\n",
      "  \"lc1\": \"G\",\n",
      "  \"lc2\": \"700\",\n",
      "  \"lc_class_from_lc\": true,\n",
      "  \"literary_form\": \"Not fiction\",\n",
      "  \"marc_record_created\": \"1986-09-10\",\n",
      "  \"permalink\": \"https://babel.hathitrust.org/cgi/pt?id=uc1.$b556662\",\n",
      "  \"record_date\": 1901,\n",
      "  \"resource_type\": \"book\",\n",
      "  \"rights_changed_date\": \"2015-01-29\",\n",
      "  \"scanner\": \"google\",\n",
      "  \"searchstring\": \"<a href=https://babel.hathitrust.org/cgi/pt?id=uc1.$b556662><em>Farther north than Nansen, being the voyage of the Polar Star,</em> (1901)\",\n",
      "  \"serial_killer_guess\": \"book\",\n",
      "  \"subject_places\": [\n",
      "    \"r------\"\n",
      "  ],\n",
      "  \"target_audience\": \"Unknown or not specified\",\n",
      "  \"title\": \"Farther north than Nansen, being the voyage of the Polar Star,\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"cataloging_source\": \" \",\n",
      "  \"cntry\": \"enk\",\n",
      "  \"contributing_library\": \"Harvard University\",\n",
      "  \"date\": 1901,\n",
      "  \"filename\": \"hvd.hnuv8p\",\n",
      "  \"first_author_birth\": 1873,\n",
      "  \"first_author_death\": 1933,\n",
      "  \"first_author_name\": \"Savoia, Luigi Amedeo di, duca degli Abruzzi, 1873-1933.\",\n",
      "  \"first_place\": \"London,\",\n",
      "  \"first_publisher\": \"H.W. Bell,\",\n",
      "  \"government_document\": \" \",\n",
      "  \"item_date\": 1901,\n",
      "  \"language\": \"eng\",\n",
      "  \"lc0\": \"G\",\n",
      "  \"lc1\": \"G\",\n",
      "  \"lc2\": \"700\",\n",
      "  \"lc_class_from_lc\": true,\n",
      "  \"literary_form\": \"Not fiction\",\n",
      "  \"marc_record_created\": \"1986-09-10\",\n",
      "  \"permalink\": \"https://babel.hathitrust.org/cgi/pt?id=hvd.hnuv8p\",\n",
      "  \"record_date\": 1901,\n",
      "  \"resource_type\": \"book\",\n",
      "  \"rights_changed_date\": \"2015-01-28\",\n",
      "  \"scanner\": \"google\",\n",
      "  \"searchstring\": \"<a href=https://babel.hathitrust.org/cgi/pt?id=hvd.hnuv8p><em>Farther north than Nansen, being the voyage of the Polar Star,</em> (1901)\",\n",
      "  \"serial_killer_guess\": \"book\",\n",
      "  \"subject_places\": [\n",
      "    \"r------\"\n",
      "  ],\n",
      "  \"target_audience\": \"Unknown or not specified\",\n",
      "  \"title\": \"Farther north than Nansen, being the voyage of the Polar Star,\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"cataloging_source\": \" \",\n",
      "  \"cntry\": \"enk\",\n",
      "  \"contributing_library\": \"University of Michigan\",\n",
      "  \"date\": 1901,\n",
      "  \"filename\": \"mdp.39015070307239\",\n",
      "  \"first_author_birth\": 1873,\n",
      "  \"first_author_death\": 1933,\n",
      "  \"first_author_name\": \"Savoia, Luigi Amedeo di, duca degli Abruzzi, 1873-1933.\",\n",
      "  \"first_place\": \"London,\",\n",
      "  \"first_publisher\": \"H.W. Bell,\",\n",
      "  \"government_document\": \" \",\n",
      "  \"item_date\": 1901,\n",
      "  \"language\": \"eng\",\n",
      "  \"lc0\": \"G\",\n",
      "  \"lc1\": \"G\",\n",
      "  \"lc2\": \"700\",\n",
      "  \"lc_class_from_lc\": true,\n",
      "  \"literary_form\": \"Not fiction\",\n",
      "  \"marc_record_created\": \"1986-09-10\",\n",
      "  \"permalink\": \"https://babel.hathitrust.org/cgi/pt?id=mdp.39015070307239\",\n",
      "  \"record_date\": 1901,\n",
      "  \"resource_type\": \"book\",\n",
      "  \"rights_changed_date\": \"2015-01-29\",\n",
      "  \"scanner\": \"google\",\n",
      "  \"searchstring\": \"<a href=https://babel.hathitrust.org/cgi/pt?id=mdp.39015070307239><em>Farther north than Nansen, being the voyage of the Polar Star,</em> (1901)\",\n",
      "  \"serial_killer_guess\": \"book\",\n",
      "  \"subject_places\": [\n",
      "    \"r------\"\n",
      "  ],\n",
      "  \"target_audience\": \"Unknown or not specified\",\n",
      "  \"title\": \"Farther north than Nansen, being the voyage of the Polar Star,\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"cataloging_source\": \"u\",\n",
      "  \"cntry\": \"|||\",\n",
      "  \"contributing_library\": \"University of Michigan\",\n",
      "  \"date\": 1920,\n",
      "  \"filename\": \"mdp.39015026989692\",\n",
      "  \"first_author_birth\": 1874,\n",
      "  \"first_author_death\": 1943,\n",
      "  \"first_author_name\": \"Elbogen, Ismar, 1874-1943.\",\n",
      "  \"first_place\": \"Leipzig,\",\n",
      "  \"first_publisher\": \"B.G. Teubner,\",\n",
      "  \"government_document\": \"|\",\n",
      "  \"item_date\": 1920,\n",
      "  \"language\": \"ger\",\n",
      "  \"literary_form\": \"No attempt to code\",\n",
      "  \"marc_record_created\": \"1988-07-15\",\n",
      "  \"permalink\": \"https://babel.hathitrust.org/cgi/pt?id=mdp.39015026989692\",\n",
      "  \"record_date\": 1920,\n",
      "  \"resource_type\": \"book\",\n",
      "  \"rights_changed_date\": \"2013-08-01\",\n",
      "  \"scanner\": \"google\",\n",
      "  \"searchstring\": \"<a href=https://babel.hathitrust.org/cgi/pt?id=mdp.39015026989692><em>Geschichte der Juden seit dem Untergang des j\\u00fcdischen Staates,</em> (1920)\",\n",
      "  \"serial_killer_guess\": \"book\",\n",
      "  \"target_audience\": \"Unknown or not specified\",\n",
      "  \"title\": \"Geschichte der Juden seit dem Untergang des j\\u00fcdischen Staates,\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"cataloging_source\": \"u\",\n",
      "  \"cntry\": \"|||\",\n",
      "  \"contributing_library\": \"University of Michigan\",\n",
      "  \"date\": 1719,\n",
      "  \"filename\": \"mdp.39015012372366\",\n",
      "  \"first_author_birth\": 1686,\n",
      "  \"first_author_death\": 1762,\n",
      "  \"first_author_name\": \"Rousset de Missy, Jean, 1686-1762.\",\n",
      "  \"first_place\": \"London,\",\n",
      "  \"first_publisher\": \"S. Illidge [etc.]\",\n",
      "  \"government_document\": \"|\",\n",
      "  \"item_date\": 1719,\n",
      "  \"language\": \"eng\",\n",
      "  \"lc0\": \"D\",\n",
      "  \"lc1\": \"DP\",\n",
      "  \"lc2\": \"197.\",\n",
      "  \"lc_class_from_lc\": false,\n",
      "  \"literary_form\": \"No attempt to code\",\n",
      "  \"marc_record_created\": \"1988-07-15\",\n",
      "  \"permalink\": \"https://babel.hathitrust.org/cgi/pt?id=mdp.39015012372366\",\n",
      "  \"record_date\": 1719,\n",
      "  \"resource_type\": \"book\",\n",
      "  \"rights_changed_date\": \"2013-09-17\",\n",
      "  \"scanner\": \"google\",\n",
      "  \"searchstring\": \"<a href=https://babel.hathitrust.org/cgi/pt?id=mdp.39015012372366><em>The history of Cardinal Alberoni; chief favourite of Their Catholick Majesties; and universal minister of the Spanish monarchy; from his birth to the year 1719. To which are added, Considerations upon the present state of the Spanish monarchy.</em> (1719)\",\n",
      "  \"serial_killer_guess\": \"book\",\n",
      "  \"target_audience\": \"Unknown or not specified\",\n",
      "  \"title\": \"The history of Cardinal Alberoni; chief favourite of Their Catholick Majesties; and universal minister of the Spanish monarchy; from his birth to the year 1719. To which are added, Considerations upon the present state of the Spanish monarchy.\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"cataloging_source\": \"d\",\n",
      "  \"cntry\": \"|||\",\n",
      "  \"contributing_library\": \"University of Michigan\",\n",
      "  \"date\": 1975,\n",
      "  \"filename\": \"mdp.39015036885344\",\n",
      "  \"first_place\": \"[Washington, D. C. :\",\n",
      "  \"first_publisher\": \"Systems and Procedures Exchange Center,\",\n",
      "  \"government_document\": \"|\",\n",
      "  \"item_date\": 1975,\n",
      "  \"language\": \"eng\",\n",
      "  \"literary_form\": \"No attempt to code\",\n",
      "  \"marc_record_created\": \"1988-07-15\",\n",
      "  \"permalink\": \"https://babel.hathitrust.org/cgi/pt?id=mdp.39015036885344\",\n",
      "  \"record_date\": 1975,\n",
      "  \"resource_type\": \"book\",\n",
      "  \"rights_changed_date\": \"2014-07-19\",\n",
      "  \"scanner\": \"google\",\n",
      "  \"searchstring\": \"<a href=https://babel.hathitrust.org/cgi/pt?id=mdp.39015036885344><em>[SPEC kit on staff associations]</em> (1975)\",\n",
      "  \"serial_killer_guess\": \"book\",\n",
      "  \"target_audience\": \"Unknown or not specified\",\n",
      "  \"title\": \"[SPEC kit on staff associations]\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"cataloging_source\": \"d\",\n",
      "  \"cntry\": \"ncu\",\n",
      "  \"contributing_library\": \"nrlf\",\n",
      "  \"date\": 1973,\n",
      "  \"filename\": \"uc1.d2566940\",\n",
      "  \"first_place\": \"Research Triangle Park, N.C. :\",\n",
      "  \"first_publisher\": \"Environmental Protection Agency, Office of Air and Water Programs, Office of Air Quality Planning and Standards ;\",\n",
      "  \"government_document\": \"f\",\n",
      "  \"item_date\": 1973,\n",
      "  \"language\": \"eng\",\n",
      "  \"literary_form\": \"Not fiction\",\n",
      "  \"marc_record_created\": \"1974-10-23\",\n",
      "  \"permalink\": \"https://babel.hathitrust.org/cgi/pt?id=uc1.d2566940\",\n",
      "  \"record_date\": 1973,\n",
      "  \"resource_type\": \"book\",\n",
      "  \"rights_changed_date\": \"2016-04-15\",\n",
      "  \"scanner\": \"google\",\n",
      "  \"searchstring\": \"<a href=https://babel.hathitrust.org/cgi/pt?id=uc1.d2566940><em>Control techniques for asbestos air pollutants /</em> (1973)\",\n",
      "  \"serial_killer_guess\": \"book\",\n",
      "  \"target_audience\": \"Unknown or not specified\",\n",
      "  \"title\": \"Control techniques for asbestos air pollutants /\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bookwormMARC.bookwormMARC import BRecord\n",
    "\n",
    "n=0\n",
    "for rec in all_files:\n",
    "    if random.random()>.01:\n",
    "        continue\n",
    "    for entry in rec.hathi_bookworm_dicts():\n",
    "        # Pretty print the dictionary entry.\n",
    "        print json.dumps(entry,sort_keys=True, indent=2, separators=(',', ': ') )\n",
    "        print \"\"\n",
    "    n+=1\n",
    "    if n>4:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Experimental: testing the goodness of record 043 codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    all_files = hathi_record_yielder()\n",
    "    knowledge = open(\"/drobo/knowledge_directions.tsv\",\"w\")\n",
    "\n",
    "    for record in all_files:\n",
    "        if record['043'] is not None:\n",
    "            try:\n",
    "                dicto = record.bookworm_dict()\n",
    "                subjects = dicto['subject_places']\n",
    "                p1 = record.first_place()\n",
    "                cntry = dicto['cntry']\n",
    "                year = dicto['date']\n",
    "                for subject in subjects:\n",
    "                    knowledge.write(\"\\t\".join(map(str,[subject,p1,year,cntry,record['001'].value(),dicto['title'].encode(\"utf-8\")]))+ \"\\n\")\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The world of available fields\n",
    "\n",
    "This code creates a list of fields that appear in more than 10% of a randomly selected subset of records. They include the control fields; author and title information; and some more esoteric things including country of study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "n = 0\n",
    "global_counts = defaultdict(int)\n",
    "\n",
    "for record in all_files:\n",
    "    if random.random() >.2:\n",
    "        continue\n",
    "    already_seen = set([])\n",
    "    n+=1\n",
    "    from collections import defaultdict\n",
    "    for dicto in record.as_dict()['fields']:\n",
    "        name = dicto.keys()[0]\n",
    "        if 'subfields' in dicto[name]:\n",
    "            for subfield in dicto[name]['subfields']:\n",
    "                tupo = (name,subfield.keys()[0])\n",
    "        else:\n",
    "            tupo = (name,None)\n",
    "        if not tupo in already_seen:\n",
    "            global_counts[tupo] +=1\n",
    "            already_seen.add(tupo)\n",
    "    if n > 10000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [((k,v),count) for ((k,v),count) in global_counts.iteritems()]\n",
    "a.sort()\n",
    "for elem in a:\n",
    "    if elem[1] > 1000:\n",
    "        print elem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better years\n",
    "\n",
    "One of the big things I've noticed is that the 974 field has better year information than the record information, such as individual fields. \n",
    "\n",
    "The following block shows that something like 1 in 3 items, in about one in ten records, have a different entry in the 974y field from the native date field. That suggests huge possibilities for improving dates if we're not already using the 974y fields: I suspect we are not based on the serial volumes that include 974y fields I see in the online browser.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 1001 records and 0 out of 0 items have differing dates\n"
     ]
    }
   ],
   "source": [
    "all_files = hathi_record_yielder()\n",
    "\n",
    "import collections\n",
    "\n",
    "records = 0\n",
    "diff_records = 0\n",
    "items = 0\n",
    "diff_items = 0\n",
    "date_diffs = collections.defaultdict(int)\n",
    "for rec in all_files:\n",
    "    if random.random() > .1:\n",
    "        # Print just one in one hundred files each time for debugging\n",
    "        continue\n",
    "    records += 1\n",
    "    line_counted = False\n",
    "    for dicto in rec.hathi_bookworm_dicts():\n",
    "        try:\n",
    "            if dicto[\"item_date\"] != dicto[\"record_date\"]:\n",
    "                date_diffs[(dicto[\"item_date\"],dicto[\"record_date\"])] += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if records>1000:\n",
    "        break\n",
    "print \"%i out of %i records and %i out of %i items have differing dates\" %(diff_records,records,diff_items,items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing differences in dates between 974 and the main MARC record\n",
    "\n",
    "]The most common pattern is that I'm replacing a \"None\" value with an actual year, or vice versa. It would be wise to see if there isn't sometimes a better solution than the Nones for the original fields. (Eg; am I overrelying on F008?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flattened = sorted([(-val,f008,f974,val) for ((f974,f008),val) in date_diffs.iteritems()])\n",
    "flattened[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at only places where we have years, most are the realm of reasonableness here.\n",
    "(With just 1000 examples, I'm certainly getting a lot of repeat entries.)\n",
    "\n",
    "There are, though, a number of places where f974 instates an earlier entry than does the native date field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flattened = sorted([(-val,f008,f974,val) for ((f974,f008),val) in date_diffs.iteritems() \n",
    "                    if f974 is not None and f008 is not None])\n",
    "flattened[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look to see what those are. Here are thirty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records = 0\n",
    "for rec in all_files:\n",
    "    if random.random() > .5:\n",
    "        # Print just one in two for debugging\n",
    "        continue\n",
    "    rec.__class__ = BRecord\n",
    "    for field in rec.get_fields('974'):\n",
    "        items += 1\n",
    "        if str(field['y']) != str(rec.date()) and field['y'] is not None and rec.date() is not None:\n",
    "            if int(field['y']) < int(rec.date()):\n",
    "                records += 1\n",
    "                print rec\n",
    "    if records>30:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic problem in all of these seems to be that in the original record, field 260c and field 008 disagree on the date. Pymarc prefers 260 in these cases; Zephir prefers field 008. Fair enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cataloging Errors: What country is Vienna in?\n",
    "\n",
    "I've noticed that cataloging librarians often just dump the city \"Wien\" into Germany because, I guess, they look only at the language. How often does this happen? Here's some code to check, 1000 entries at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "right = 0\n",
    "wrong = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('oops', u'gw ', u'Wien :')\n",
      "('oops', u'gw ', u'Wien,')\n",
      "('oops', u'gw ', u'Wien :')\n",
      "('oops', u'ohu', u'Wien,')\n",
      "('oops', u'af ', u'Wien,')\n",
      "('oops', u'gw ', u'Wien,')\n",
      "So far, 6 wrong and 51 right (10.53%)\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for rec in all_files:\n",
    "    n += 1\n",
    "    if n>10000:\n",
    "        break\n",
    "    dicto =  rec.bookworm_dict()\n",
    "    try:\n",
    "        if \"Wien\" in dicto['first_place'] and not \"und Wien\" in dicto['first_place']:\n",
    "            if dicto['cntry'] != 'au ' and dicto['cntry'] != 'au#' and dicto['cntry'] != \"xx \":\n",
    "                wrong += 1\n",
    "                #a = bookwormMARC.bookwormMARC.F008(rec)\n",
    "                print (\"oops\", dicto['cntry'],dicto['first_place'])\n",
    "            else:\n",
    "                #print dicto['cntry']\n",
    "                right += 1\n",
    "    except KeyError:\n",
    "        continue\n",
    "try:\n",
    "    print \"So far, {} wrong and {} right ({:0.2f}%)\".format(wrong,right,100*float(wrong)/float(wrong+right))\n",
    "except ZeroDivisionError:\n",
    "    print \"Haven't found any yet: try running again\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "\n",
    "dictee = defaultdict(int)\n",
    "\n",
    "for rec in all_files:\n",
    "    n+=1\n",
    "    if n > 10:\n",
    "        break\n",
    "        \n",
    "    for item in rec.hathi_bookworm_dicts():\n",
    "        if item['serial_killer_guess'] != item['resource_type']:\n",
    "            print item['title']\n",
    "        try:\n",
    "            dictee[(item['serial_killer_guess'],item['resource_type'])] += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "        break\n",
    "for (k,v) in dictee.iteritems():\n",
    "    print (k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "testrow = \"CLASS C - AUXILIARY SCIENCES OF HISTORY\"\n",
    "file = open(\"/drobo/hathi_metadata/vocabularies/lc_class.txt\",\"r\")\n",
    "line = line.rstrip(\"\\n\")\n",
    "line = line.rstrip(\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_row(string):\n",
    "    \"\"\"\n",
    "    Each row is 4-tuple; the level,\n",
    "    lower bound,\n",
    "    the upper bound, and the label.\n",
    "    \"\"\"\n",
    "    l1 = re.search(r\"CLASS ([A-Z]) - (\\w+)\",string)\n",
    "    if l1:\n",
    "        groups = l1.groups()\n",
    "        return (0,groups[0],groups[0],groups[1])\n",
    "    l2 = re.search(r\"Subclass ([A-Z]{1,3})\",string)\n",
    "    if l2:\n",
    "        groups = l2.groups()\n",
    "        return (1,groups[0],groups[0],None)\n",
    "    l3 = re.search(r'([A-Z]+)\\(?(\\d+(?:\\.[A-Z]?\\d*)?)\\)?-?\\(?(\\d+(?:\\.[A-Z]?\\d*)?)?\\)?(\\t+)(.*)',string)\n",
    "    if l3:\n",
    "        groups = list(l3.groups())\n",
    "        if groups[2] is None:\n",
    "            groups[2] = groups[1]\n",
    "        return (1 + len(groups[3]),groups[1],groups[2],groups[4])\n",
    "\n",
    "line = file.readline()\n",
    "if line ==\"\\n\": line = file.readline()\n",
    "\n",
    "print line\n",
    "print parse_row(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(20):\n",
    "    foo = all_files.next()\n",
    "    print foo['008'].data[32] + '-' + foo['008'].data[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
